{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {
        "height": "583px",
        "left": "0px",
        "right": "20px",
        "top": "107px",
        "width": "212px"
      },
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "colab": {
      "name": "1.1 Constant_features.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay10949/AnalyticsAndML/blob/master/FeatureSelection/FilterMethods/1_1_Constant_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54dBUncDgyAa",
        "colab_type": "text"
      },
      "source": [
        "## Constant features\n",
        "\n",
        "Constant features are those that show the same value, just one value, for all the observations of the dataset. This is, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.\n",
        "\n",
        "Identifying and removing constant features, is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
        "\n",
        "Here I will demonstrate how to identify constant features using the Santander Customer Satisfaction dataset from Kaggle. \n",
        "\n",
        "To identify constant features, we can use the VarianceThreshold function from sklearn, or we can code it ourselves. I will show 2 snippets of code with both procedures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svfu9hlVgyAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1btnJAggyBN",
        "colab_type": "text"
      },
      "source": [
        "## Removing constant features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BdnK7wIgyBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a655ec3-9e5a-42a9-93b4-7d7b684e49c7"
      },
      "source": [
        "# load the Santander customer satisfaction dataset from Kaggle\n",
        "# I load just a few rows for the demonstration\n",
        "\n",
        "data = pd.read_csv('santander.csv', nrows=50000)\n",
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tDtoARbvgyBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41e40724-5350-459c-c992-3dda96ae881b"
      },
      "source": [
        "# check the presence of null data.\n",
        "# The snippets below will be able to compare nan values between 2 columns,\n",
        "# so in principle missing data are not a problem.\n",
        "# in any case, we see that there are no missing data in this dataset\n",
        "\n",
        "[col for col in data.columns if data[col].isnull().sum() > 0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb6yyWbugyB2",
        "colab_type": "text"
      },
      "source": [
        "### Important\n",
        "\n",
        "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmVisePYgyB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "129f179b-0e24-4a64-d00b-e24b06c78b75"
      },
      "source": [
        "# separate dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['TARGET'], axis=1),\n",
        "    data['TARGET'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 370), (15000, 370))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP88jCLFgyCQ",
        "colab_type": "text"
      },
      "source": [
        "### Using variance threshold from sklearn\n",
        "\n",
        "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesnâ€™t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56VibvK2gyCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b3fe5d7-043a-4047-a2e6-5ecf471940b2"
      },
      "source": [
        "sel = VarianceThreshold(threshold=0)\n",
        "sel.fit(X_train)  # fit finds the features with zero variance"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VarianceThreshold(threshold=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cu83aVpgyCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4187c098-df08-46f3-af8d-7acb29b3a37a"
      },
      "source": [
        "# get_support is a boolean vector that indicates which features are retained\n",
        "# if we sum over get_support, we get the number of features that are not constant\n",
        "sum(sel.get_support())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRgmJYBRgyCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec704448-0fd9-4e12-820a-49e997439653"
      },
      "source": [
        "# another way of finding non-constant features is like this:\n",
        "len(X_train.columns[sel.get_support()])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "C2eGkfLlgyDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92a27c62-91ce-4c42-e5c9-54a6cee7c3f3"
      },
      "source": [
        "# finally we can print the constant features\n",
        "print(\n",
        "    len([\n",
        "        x for x in X_train.columns\n",
        "        if x not in X_train.columns[sel.get_support()]\n",
        "    ]))\n",
        "\n",
        "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ind_var2_0',\n",
              " 'ind_var2',\n",
              " 'ind_var13_medio_0',\n",
              " 'ind_var13_medio',\n",
              " 'ind_var27_0',\n",
              " 'ind_var28_0',\n",
              " 'ind_var28',\n",
              " 'ind_var27',\n",
              " 'ind_var34_0',\n",
              " 'ind_var34',\n",
              " 'ind_var41',\n",
              " 'ind_var46_0',\n",
              " 'ind_var46',\n",
              " 'num_var13_medio_0',\n",
              " 'num_var13_medio',\n",
              " 'num_var27_0',\n",
              " 'num_var28_0',\n",
              " 'num_var28',\n",
              " 'num_var27',\n",
              " 'num_var34_0',\n",
              " 'num_var34',\n",
              " 'num_var41',\n",
              " 'num_var46_0',\n",
              " 'num_var46',\n",
              " 'saldo_var13_medio',\n",
              " 'saldo_var28',\n",
              " 'saldo_var27',\n",
              " 'saldo_var34',\n",
              " 'saldo_var41',\n",
              " 'saldo_var46',\n",
              " 'delta_imp_amort_var34_1y3',\n",
              " 'delta_imp_reemb_var33_1y3',\n",
              " 'delta_num_reemb_var33_1y3',\n",
              " 'imp_amort_var18_hace3',\n",
              " 'imp_amort_var34_hace3',\n",
              " 'imp_amort_var34_ult1',\n",
              " 'imp_reemb_var13_hace3',\n",
              " 'imp_reemb_var17_hace3',\n",
              " 'imp_reemb_var33_hace3',\n",
              " 'imp_reemb_var33_ult1',\n",
              " 'imp_trasp_var17_out_hace3',\n",
              " 'imp_trasp_var33_out_hace3',\n",
              " 'imp_venta_var44_hace3',\n",
              " 'num_var2_0_ult1',\n",
              " 'num_var2_ult1',\n",
              " 'num_meses_var13_medio_ult3',\n",
              " 'num_reemb_var13_hace3',\n",
              " 'num_reemb_var17_hace3',\n",
              " 'num_reemb_var33_hace3',\n",
              " 'num_reemb_var33_ult1',\n",
              " 'num_trasp_var17_out_hace3',\n",
              " 'num_trasp_var33_out_hace3',\n",
              " 'num_venta_var44_hace3',\n",
              " 'saldo_var2_ult1',\n",
              " 'saldo_medio_var13_medio_hace2',\n",
              " 'saldo_medio_var13_medio_hace3',\n",
              " 'saldo_medio_var13_medio_ult1',\n",
              " 'saldo_medio_var13_medio_ult3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh09INodgyDM",
        "colab_type": "text"
      },
      "source": [
        "We can see that 58 columns / variables are constant. This means that 58 variables show the same value, just one value, for all the observations of the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X980DwhXgyDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "722a702e-f6ee-4179-ab28-821470cec983"
      },
      "source": [
        "# let's visualise the values of one of the constant variables\n",
        "# as an example\n",
        "\n",
        "X_train['ind_var2_0'].unique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh__cgNjgyDi",
        "colab_type": "text"
      },
      "source": [
        "We then use the transform function to reduce the training and testing sets. See below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsaeJ1aRgyDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "7c1ed6ff-d85c-4edc-aaee-e6407216f57d"
      },
      "source": [
        "X_train = sel.transform(X_train)\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-098777caefc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X has a different shape than during fitting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has a different shape than during fitting."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMq9HlgTgyDu",
        "colab_type": "text"
      },
      "source": [
        "### Coding it ourselves\n",
        "\n",
        "In the following cells, I will show an alternative to the VarianceThreshold function of sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7Y3oBAgyDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef2df778-0795-4ef1-f709-6cdbcc50cb69"
      },
      "source": [
        "# load the dataset again\n",
        "data = pd.read_csv('santander.csv', nrows=50000)\n",
        "\n",
        "# separate train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['TARGET'], axis=1),\n",
        "    data['TARGET'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 370), (15000, 370))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pSNqp7SHgyEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "322a79ae-7d8f-428c-b887-2670bf5286ee"
      },
      "source": [
        "# short and easy: find constant features\n",
        "# in this case, all features are numeric, so this will suffice\n",
        "\n",
        "constant_features = [\n",
        "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
        "]\n",
        "\n",
        "len(constant_features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QjYGWv5tgyEK",
        "colab_type": "code",
        "colab": {},
        "outputId": "90ec95a5-0147-48d2-c34d-4ed351cb9ec7"
      },
      "source": [
        "# we can then drop these columns from the train and test sets\n",
        "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 312), (15000, 312))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0bfOiPcgyET",
        "colab_type": "text"
      },
      "source": [
        "We see how by removing constant features, we managed to reduced the feature space quite a bit.\n",
        "\n",
        "Both varianceThreshold and the snippet of code I provided work with numerical variables. What can we do to find constant categorical variables?\n",
        "\n",
        "One alternatively is to encode the categories as numbers and then use the code above. But then you will put effort in pre-processing variables that are not informative.\n",
        "\n",
        "Alternatively, you can use the code below.\n",
        "\n",
        "### Removing constant features for categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GjHTyatgyEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bc32a66-4dfe-41d5-cdb7-b613acbed233"
      },
      "source": [
        "# load the dataset again\n",
        "data = pd.read_csv('santander.csv', nrows=50000)\n",
        "\n",
        "# separate train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['TARGET'], axis=1),\n",
        "    data['TARGET'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 370), (15000, 370))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0atCWZYGgyEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "a642f724-120e-4821-f533-c623e7d9cb10"
      },
      "source": [
        "# I will transform all these numeric features into\n",
        "# categorical features for the demonstration\n",
        "# to simulate that they are categorical\n",
        "\n",
        "X_train = X_train.astype('O')\n",
        "X_train.dtypes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                         object\n",
              "var3                       object\n",
              "var15                      object\n",
              "imp_ent_var16_ult1         object\n",
              "imp_op_var39_comer_ult1    object\n",
              "                            ...  \n",
              "saldo_medio_var44_hace2    object\n",
              "saldo_medio_var44_hace3    object\n",
              "saldo_medio_var44_ult1     object\n",
              "saldo_medio_var44_ult3     object\n",
              "var38                      object\n",
              "Length: 370, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yS_mdAFHgyEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "758a8db3-d8a9-467a-ec36-2fc804836a0b"
      },
      "source": [
        "# and now find those columns that contain only 1 label:\n",
        "constant_features = [\n",
        "    feat for feat in X_train.columns if len(X_train[feat].unique()) == 1\n",
        "]\n",
        "\n",
        "len(constant_features)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailTCDgOgyEw",
        "colab_type": "text"
      },
      "source": [
        "Same as before, we observe 58 variables that show only 1 value across all the observations of the dataset. We can appreciate the usefulness of looking out for constant variables at the beginning of any modeling exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umleTvgegyE0",
        "colab_type": "text"
      },
      "source": [
        "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
      ]
    }
  ]
}