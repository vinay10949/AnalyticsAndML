{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "colab": {
      "name": "3.1 Lasso.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay10949/AnalyticsAndML/blob/master/FeatureSelection/EmbeddedMethods/3_1_Lasso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr5PROFQfVV_",
        "colab_type": "text"
      },
      "source": [
        "## Lasso regularisation\n",
        "\n",
        "Regularisation consists in adding a penalty to the different parameters of the machine learning model to reduce the freedom of the model and in other words to avoid overfitting. In linear model regularisation, the penalty is applied over the coefficients that multiply each of the predictors. From the different types of regularisation, Lasso or l1 has the property that is able to shrink some of the coefficients to zero. Therefore, that feature can be removed from the model.\n",
        "\n",
        "I will demonstrate how to select features using the Lasso regularisation on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afot2mqffkmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "2987fc8b-22d3-4f68-90b3-148db542db5d"
      },
      "source": [
        "!pip install --user kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"vinay10949\",\"key\":\"59c4901452f76ce62979e5b0997e240b\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRytu6MFfyvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e6d4b573-9a6a-4e52-c2d3-0083c5b194a9"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c bnp-paribas-cardif-claims-management\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 67% 33.0M/49.4M [00:00<00:00, 38.6MB/s]\n",
            "100% 49.4M/49.4M [00:00<00:00, 91.6MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/162k [00:00<?, ?B/s]\n",
            "100% 162k/162k [00:00<00:00, 141MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 67% 33.0M/49.4M [00:00<00:00, 59.6MB/s]\n",
            "100% 49.4M/49.4M [00:00<00:00, 125MB/s] \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEysyvB0fVWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz33hO0WfVWh",
        "colab_type": "text"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9duYAb6IfVWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b122801-63f3-43e8-dd69-48d960ab5715"
      },
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('train.csv', nrows=50000)\n",
        "data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 133)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIE0-mh9fVWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "19d24f83-ff12-4f0a-8247-8f4a0992b075"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>v11</th>\n",
              "      <th>v12</th>\n",
              "      <th>v13</th>\n",
              "      <th>v14</th>\n",
              "      <th>v15</th>\n",
              "      <th>v16</th>\n",
              "      <th>v17</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "      <th>v28</th>\n",
              "      <th>v29</th>\n",
              "      <th>v30</th>\n",
              "      <th>v31</th>\n",
              "      <th>v32</th>\n",
              "      <th>v33</th>\n",
              "      <th>v34</th>\n",
              "      <th>v35</th>\n",
              "      <th>v36</th>\n",
              "      <th>v37</th>\n",
              "      <th>v38</th>\n",
              "      <th>...</th>\n",
              "      <th>v92</th>\n",
              "      <th>v93</th>\n",
              "      <th>v94</th>\n",
              "      <th>v95</th>\n",
              "      <th>v96</th>\n",
              "      <th>v97</th>\n",
              "      <th>v98</th>\n",
              "      <th>v99</th>\n",
              "      <th>v100</th>\n",
              "      <th>v101</th>\n",
              "      <th>v102</th>\n",
              "      <th>v103</th>\n",
              "      <th>v104</th>\n",
              "      <th>v105</th>\n",
              "      <th>v106</th>\n",
              "      <th>v107</th>\n",
              "      <th>v108</th>\n",
              "      <th>v109</th>\n",
              "      <th>v110</th>\n",
              "      <th>v111</th>\n",
              "      <th>v112</th>\n",
              "      <th>v113</th>\n",
              "      <th>v114</th>\n",
              "      <th>v115</th>\n",
              "      <th>v116</th>\n",
              "      <th>v117</th>\n",
              "      <th>v118</th>\n",
              "      <th>v119</th>\n",
              "      <th>v120</th>\n",
              "      <th>v121</th>\n",
              "      <th>v122</th>\n",
              "      <th>v123</th>\n",
              "      <th>v124</th>\n",
              "      <th>v125</th>\n",
              "      <th>v126</th>\n",
              "      <th>v127</th>\n",
              "      <th>v128</th>\n",
              "      <th>v129</th>\n",
              "      <th>v130</th>\n",
              "      <th>v131</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.335739</td>\n",
              "      <td>8.727474</td>\n",
              "      <td>C</td>\n",
              "      <td>3.921026</td>\n",
              "      <td>7.915266</td>\n",
              "      <td>2.599278</td>\n",
              "      <td>3.176895</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>9.999999</td>\n",
              "      <td>0.503281</td>\n",
              "      <td>16.434108</td>\n",
              "      <td>6.085711</td>\n",
              "      <td>2.866830</td>\n",
              "      <td>11.636387</td>\n",
              "      <td>1.355013</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>3.670350</td>\n",
              "      <td>0.106720</td>\n",
              "      <td>0.148883</td>\n",
              "      <td>18.869283</td>\n",
              "      <td>7.730923</td>\n",
              "      <td>XDX</td>\n",
              "      <td>-1.716131e-08</td>\n",
              "      <td>C</td>\n",
              "      <td>0.139412</td>\n",
              "      <td>1.720818</td>\n",
              "      <td>3.393503</td>\n",
              "      <td>0.590122</td>\n",
              "      <td>8.880867</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>1.083033</td>\n",
              "      <td>1.010829</td>\n",
              "      <td>7.270147</td>\n",
              "      <td>8.375452</td>\n",
              "      <td>11.326592</td>\n",
              "      <td>0.454546</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.442252</td>\n",
              "      <td>5.814018</td>\n",
              "      <td>3.517720</td>\n",
              "      <td>0.462019</td>\n",
              "      <td>7.436824</td>\n",
              "      <td>5.454545</td>\n",
              "      <td>8.877414</td>\n",
              "      <td>1.191337</td>\n",
              "      <td>19.470199</td>\n",
              "      <td>8.389237</td>\n",
              "      <td>2.757375</td>\n",
              "      <td>4.374296</td>\n",
              "      <td>1.574039</td>\n",
              "      <td>0.007294</td>\n",
              "      <td>12.579184</td>\n",
              "      <td>E</td>\n",
              "      <td>2.382692</td>\n",
              "      <td>3.930922</td>\n",
              "      <td>B</td>\n",
              "      <td>0.433213</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.634907</td>\n",
              "      <td>2.857144</td>\n",
              "      <td>1.951220</td>\n",
              "      <td>6.592012</td>\n",
              "      <td>5.909091</td>\n",
              "      <td>-6.297423e-07</td>\n",
              "      <td>1.059603</td>\n",
              "      <td>0.803572</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.989780</td>\n",
              "      <td>0.035754</td>\n",
              "      <td>AU</td>\n",
              "      <td>1.804126</td>\n",
              "      <td>3.113719</td>\n",
              "      <td>2.024285</td>\n",
              "      <td>0</td>\n",
              "      <td>0.636365</td>\n",
              "      <td>2.857144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.191265</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.301630</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.312910</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.507647</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.636386</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.763110</td>\n",
              "      <td>GUV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>3.056144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.615077</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.579479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.303967</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.505335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>1.825361</td>\n",
              "      <td>4.247858</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>U</td>\n",
              "      <td>G</td>\n",
              "      <td>10.308044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.595357</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.598896</td>\n",
              "      <td>AF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.957825</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.943877</td>\n",
              "      <td>5.310079</td>\n",
              "      <td>C</td>\n",
              "      <td>4.410969</td>\n",
              "      <td>5.326159</td>\n",
              "      <td>3.979592</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>0.019645</td>\n",
              "      <td>12.666667</td>\n",
              "      <td>0.765864</td>\n",
              "      <td>14.756098</td>\n",
              "      <td>6.384670</td>\n",
              "      <td>2.505589</td>\n",
              "      <td>9.603542</td>\n",
              "      <td>1.984127</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>3.170847</td>\n",
              "      <td>0.244541</td>\n",
              "      <td>0.144258</td>\n",
              "      <td>17.952332</td>\n",
              "      <td>5.245035</td>\n",
              "      <td>FQ</td>\n",
              "      <td>-2.785053e-07</td>\n",
              "      <td>E</td>\n",
              "      <td>0.113997</td>\n",
              "      <td>2.244897</td>\n",
              "      <td>5.306122</td>\n",
              "      <td>0.836005</td>\n",
              "      <td>7.499999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>1.454082</td>\n",
              "      <td>1.734693</td>\n",
              "      <td>4.043864</td>\n",
              "      <td>7.959184</td>\n",
              "      <td>12.730517</td>\n",
              "      <td>0.259740</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271480</td>\n",
              "      <td>5.156559</td>\n",
              "      <td>4.214944</td>\n",
              "      <td>0.309657</td>\n",
              "      <td>5.663265</td>\n",
              "      <td>5.974026</td>\n",
              "      <td>11.588858</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>15.491329</td>\n",
              "      <td>5.879353</td>\n",
              "      <td>3.292788</td>\n",
              "      <td>5.924457</td>\n",
              "      <td>1.668401</td>\n",
              "      <td>0.008275</td>\n",
              "      <td>11.670572</td>\n",
              "      <td>C</td>\n",
              "      <td>1.375753</td>\n",
              "      <td>1.184211</td>\n",
              "      <td>B</td>\n",
              "      <td>3.367348</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.205561</td>\n",
              "      <td>12.941177</td>\n",
              "      <td>3.129253</td>\n",
              "      <td>3.478911</td>\n",
              "      <td>6.233767</td>\n",
              "      <td>-2.792745e-07</td>\n",
              "      <td>2.138728</td>\n",
              "      <td>2.238806</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>2.477596</td>\n",
              "      <td>0.013452</td>\n",
              "      <td>AE</td>\n",
              "      <td>1.773709</td>\n",
              "      <td>3.922193</td>\n",
              "      <td>1.120468</td>\n",
              "      <td>2</td>\n",
              "      <td>0.883118</td>\n",
              "      <td>1.176472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.797415</td>\n",
              "      <td>8.304757</td>\n",
              "      <td>C</td>\n",
              "      <td>4.225930</td>\n",
              "      <td>11.627438</td>\n",
              "      <td>2.097700</td>\n",
              "      <td>1.987549</td>\n",
              "      <td>0.171947</td>\n",
              "      <td>8.965516</td>\n",
              "      <td>6.542669</td>\n",
              "      <td>16.347483</td>\n",
              "      <td>9.646653</td>\n",
              "      <td>3.903302</td>\n",
              "      <td>14.094723</td>\n",
              "      <td>1.945044</td>\n",
              "      <td>5.517242</td>\n",
              "      <td>3.610789</td>\n",
              "      <td>1.224114</td>\n",
              "      <td>0.231630</td>\n",
              "      <td>18.376407</td>\n",
              "      <td>7.517125</td>\n",
              "      <td>ACUE</td>\n",
              "      <td>-4.805344e-07</td>\n",
              "      <td>D</td>\n",
              "      <td>0.148843</td>\n",
              "      <td>1.308269</td>\n",
              "      <td>2.303640</td>\n",
              "      <td>8.926662</td>\n",
              "      <td>8.874521</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>1.587644</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>8.703550</td>\n",
              "      <td>8.898468</td>\n",
              "      <td>11.302795</td>\n",
              "      <td>0.433735</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.763925</td>\n",
              "      <td>5.498902</td>\n",
              "      <td>3.423944</td>\n",
              "      <td>0.832518</td>\n",
              "      <td>7.375480</td>\n",
              "      <td>6.746988</td>\n",
              "      <td>6.942002</td>\n",
              "      <td>1.334611</td>\n",
              "      <td>18.256352</td>\n",
              "      <td>8.507281</td>\n",
              "      <td>2.503055</td>\n",
              "      <td>4.872157</td>\n",
              "      <td>2.573664</td>\n",
              "      <td>0.113967</td>\n",
              "      <td>12.554274</td>\n",
              "      <td>B</td>\n",
              "      <td>2.230754</td>\n",
              "      <td>1.990131</td>\n",
              "      <td>B</td>\n",
              "      <td>2.643678</td>\n",
              "      <td>J</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.777666</td>\n",
              "      <td>10.574713</td>\n",
              "      <td>1.511063</td>\n",
              "      <td>4.949609</td>\n",
              "      <td>7.180722</td>\n",
              "      <td>5.655086e-01</td>\n",
              "      <td>1.166281</td>\n",
              "      <td>1.956521</td>\n",
              "      <td>7.018256</td>\n",
              "      <td>1.812795</td>\n",
              "      <td>0.002267</td>\n",
              "      <td>CJ</td>\n",
              "      <td>1.415230</td>\n",
              "      <td>2.954381</td>\n",
              "      <td>1.990847</td>\n",
              "      <td>1</td>\n",
              "      <td>1.677108</td>\n",
              "      <td>1.034483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.050328</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.320087</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.991098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.414567</td>\n",
              "      <td>HIT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.083151</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>14.097099</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 133 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  target        v1        v2  ...      v128  v129      v130      v131\n",
              "0   3       1  1.335739  8.727474  ...  2.024285     0  0.636365  2.857144\n",
              "1   4       1       NaN       NaN  ...  1.957825     0       NaN       NaN\n",
              "2   5       1  0.943877  5.310079  ...  1.120468     2  0.883118  1.176472\n",
              "3   6       1  0.797415  8.304757  ...  1.990847     1  1.677108  1.034483\n",
              "4   8       1       NaN       NaN  ...       NaN     0       NaN       NaN\n",
              "\n",
              "[5 rows x 133 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLBQZ416fVXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65e645b0-8ab0-48b5-be80-a3a83fd87a32"
      },
      "source": [
        "# In practice, feature selection should be done after data pre-processing,\n",
        "# so ideally, all the categorical variables are encoded into numbers,\n",
        "# and then you can assess how deterministic they are of the target\n",
        "\n",
        "# here for simplicity I will use only numerical variables\n",
        "# select numerical columns:\n",
        "\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
        "data = data[numerical_vars]\n",
        "data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 114)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJL-acVfVXR",
        "colab_type": "text"
      },
      "source": [
        "#### Important\n",
        "\n",
        "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGArUuX2fVXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94a10552-1f7c-4c8b-b630-c39a9754aa26"
      },
      "source": [
        "# separate train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['target', 'ID'], axis=1),\n",
        "    data['target'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 112), (15000, 112))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_gJFXrfVXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44f630fa-d2f8-41ec-a746-a508249a6fb2"
      },
      "source": [
        "# linear models benefit from feature scaling\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.fillna(0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tK-HIn9ffVXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here I will do the model fitting and feature selection\n",
        "# altogether in one line of code\n",
        "\n",
        "# first I specify the Logistic Regression model, and I\n",
        "# make sure I select the Lasso (l1) penalty.\n",
        "\n",
        "# Then I use the selectFromModel object from sklearn, which\n",
        "# will select in theory the features which coefficients are non-zero\n",
        "\n",
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
        "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZO0j9EfVX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "dbbd1e4d-0b40-4536-abeb-1f251f33ecd5"
      },
      "source": [
        "# this command let's me visualise those features that were kept\n",
        "sel_.get_support()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False,  True,  True,  True,  True, False,  True,\n",
              "       False,  True, False, False,  True,  True, False, False, False,\n",
              "       False, False, False,  True, False, False, False, False, False,\n",
              "       False,  True,  True,  True, False,  True, False, False, False,\n",
              "       False, False,  True,  True,  True, False, False,  True, False,\n",
              "       False, False, False, False, False,  True,  True,  True, False,\n",
              "       False, False, False, False, False, False,  True,  True,  True,\n",
              "        True,  True, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False,  True, False, False,\n",
              "       False, False,  True, False,  True, False, False, False, False,\n",
              "       False, False,  True,  True,  True,  True, False, False,  True,\n",
              "       False, False, False, False, False,  True, False, False, False,\n",
              "       False,  True,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X97daMagfVYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "218d9d2f-2ee1-4780-db60-91e115520321"
      },
      "source": [
        "# Now I make a list with the selected features\n",
        "selected_feat = X_train.columns[(sel_.get_support())]\n",
        "\n",
        "print('total features: {}'.format((X_train.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('features with coefficients shrank to zero: {}'.format(\n",
        "    np.sum(sel_.estimator_.coef_ == 0)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total features: 112\n",
            "selected features: 37\n",
            "features with coefficients shrank to zero: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvIcqlUfVYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9468d9e0-520f-47e0-db3b-36f2ae405d45"
      },
      "source": [
        "# the number of features which coefficient was shrank to zero:\n",
        "np.sum(sel_.estimator_.coef_ == 0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmDa1z2mfVYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f885605-848a-485a-e795-4a3d89599304"
      },
      "source": [
        "# we can identify the removed features like this:\n",
        "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
        "removed_feats"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhGszJhfVYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f142ed1f-580c-4b41-e9e5-76841deec6d3"
      },
      "source": [
        "# we can then remove the features from the training and testing set\n",
        "# like this\n",
        "X_train_selected = sel_.transform(X_train.fillna(0))\n",
        "X_test_selected = sel_.transform(X_test.fillna(0))\n",
        "\n",
        "X_train_selected.shape, X_test_selected.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 37), (15000, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm5qhFM_fVY2",
        "colab_type": "text"
      },
      "source": [
        "#### L2 regularisation does not shrink coefficients to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tGOWdkPfVY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1370281-a5ba-44f6-f401-e5da9e670ed5"
      },
      "source": [
        "# separate train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['target', 'ID'], axis=1),\n",
        "    data['target'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 112), (15000, 112))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhf7cFMfVZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7359f47e-5441-448a-8c7e-bb9713027247"
      },
      "source": [
        "# For comparison, I will fit a logistic regression with a\n",
        "# Ridge regularisation, and evaluate the coefficients\n",
        "\n",
        "l1_logit = LogisticRegression(C=1, penalty='l2')\n",
        "l1_logit.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
        "\n",
        "# I count the number of coefficients with zero values\n",
        "# and it is zero, as expected\n",
        "np.sum(l1_logit.coef_ == 0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liSmiRPvfVZP",
        "colab_type": "text"
      },
      "source": [
        "### Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYgMAXlnfVZR",
        "colab_type": "code",
        "colab": {},
        "outputId": "764f6b64-875d-472b-a176-beb9cf8069b1"
      },
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('houseprice.csv')\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 81)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Maju6ZpafVZY",
        "colab_type": "code",
        "colab": {},
        "outputId": "5f976d0b-356a-411c-9c7d-19f96beb6390"
      },
      "source": [
        "# In practice, feature selection should be done after data pre-processing,\n",
        "# so ideally, all the categorical variables are encoded into numbers,\n",
        "# and then you can assess how deterministic they are of the target\n",
        "\n",
        "# here for simplicity I will use only numerical variables\n",
        "# select numerical columns:\n",
        "\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
        "data = data[numerical_vars]\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJu58oBLfVZv",
        "colab_type": "code",
        "colab": {},
        "outputId": "a16cc25a-e189-4f26-9362-80bbfef5bcc2"
      },
      "source": [
        "# separate train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['SalePrice'], axis=1),\n",
        "    data['SalePrice'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1022, 37), (438, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSFKZDn6fVZ3",
        "colab_type": "code",
        "colab": {},
        "outputId": "aaf093e7-7b5c-4b77-b6ef-0032f802f9d7"
      },
      "source": [
        "# the features in the house dataset are in very\n",
        "# different scales, so it helps the regression to scale\n",
        "# them\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.fillna(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AXJQwyhVfVZ-",
        "colab_type": "code",
        "colab": {},
        "outputId": "2a999288-223e-4810-813f-d27663751d63"
      },
      "source": [
        "# here, again I will train a Lasso Linear regression and select\n",
        "# the non zero features in one line.\n",
        "# bear in mind that the linear regression object from sklearn does\n",
        "# not allow for regularisation. So If you want to make a regularised\n",
        "# linear regression you need to import specifically \"Lasso\"\n",
        "# that is the l1 version of the linear regression\n",
        "# alpha is the penalisation here, so I set it high in order\n",
        "# to force the algorithm to shrink some coefficients\n",
        "\n",
        "sel_ = SelectFromModel(Lasso(alpha=100))\n",
        "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=Lasso(alpha=100, copy_X=True, fit_intercept=True, max_iter=1000,\n",
              "   normalize=False, positive=False, precompute=False, random_state=None,\n",
              "   selection='cyclic', tol=0.0001, warm_start=False),\n",
              "        prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Iw40tqfVaJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9d6fd64-09f1-476d-90a5-43f779d6286b"
      },
      "source": [
        "sel_.get_support()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True, False,  True,  True], dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0P5fT1wfVaU",
        "colab_type": "code",
        "colab": {},
        "outputId": "b520cdbf-6cc3-4e2f-fa66-9b7529d25595"
      },
      "source": [
        "# make a list with the selected features and print the outputs\n",
        "selected_feat = X_train.columns[(sel_.get_support())]\n",
        "\n",
        "print('total features: {}'.format((X_train.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('features with coefficients shrank to zero: {}'.format(\n",
        "    np.sum(sel_.estimator_.coef_ == 0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total features: 37\n",
            "selected features: 33\n",
            "features with coefficients shrank to zero: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kxt4BTMfVah",
        "colab_type": "text"
      },
      "source": [
        "As we can see, both for linear and logistic regression we used the Lasso regularisation to remove non-important features from the dataset. Keep in mind that increasing the penalisation will increase the number of features removed. Therefore, you will need to keep an eye and monitor that you don't set a penalty too high so that to remove even important features, or too low and then not remove non-important features.\n",
        "\n",
        "Having said this, if the penalty is too high and important features are removed, you should notice a drop in the performance of the algorithm and then realise that you need to decrease the regularisation.\n",
        "\n",
        "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbH9SXKyfVal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}